{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "V9zNGvape2-I"
      },
      "source": [
        "# **Point Scanning Super Resolution (PSSR) - Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b4-r1gE7Iamv"
      },
      "source": [
        "# **1. Preparation: Set the Runtime type and mount your Google Drive**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "K5_nSag2fU94"
      },
      "source": [
        "## **1.1. Set the Runtime type**\n",
        "---\n",
        "\n",
        "<font size = 4>Go to **Runtime -> Change the Runtime type**\n",
        "\n",
        "<font size = 4>**Runtime type: Python 3** *(Python 3 is programming language in which this program is written)*\n",
        "\n",
        "<font size = 4>**Accelator: GPU** *(Graphics processing unit (GPU)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "colab_type": "code",
        "id": "BDhmUgqCStlm",
        "outputId": "67fd20f6-933e-4058-8f8f-4c320105b8aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "You have GPU access\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 10765735311409383637, name: \"/device:XLA_CPU:0\"\n",
              " device_type: \"XLA_CPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 2317427044891050265\n",
              " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n",
              " device_type: \"XLA_GPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 11729913141592060865\n",
              " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 15956161332\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 6927160916135005224\n",
              " physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"]"
            ]
          },
          "execution_count": 1,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Run this cell to check if you have GPU access\n",
        "%tensorflow_version 2.x\n",
        "\n",
        "import tensorflow as tf\n",
        "if tf.test.gpu_device_name()=='':\n",
        "  print('You do not have GPU access.') \n",
        "  print('Did you change your runtime ?') \n",
        "  print('If the runtime settings are correct then Google did not allocate GPU to your session')\n",
        "  print('Expect slow performance. To access GPU try reconnecting later')\n",
        "else:\n",
        "  print('You have GPU access')\n",
        "\n",
        "from tensorflow.python.client import device_lib \n",
        "device_lib.list_local_devices()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-oqBTeLaImnU"
      },
      "source": [
        "## **1.2. Mount your Google Drive**\n",
        "---\n",
        "<font size = 4> To use this notebook on the data present in your Google Drive, you need to mount your Google Drive to this notebook.\n",
        "\n",
        "<font size = 4> Play the cell below to mount your Google Drive and follow the link. In the new browser window, select your drive and select 'Allow', copy the code, paste into the cell and press enter. This will give Colab access to the data on the drive. \n",
        "\n",
        "<font size = 4> Once this is done, your data are available in the **Files** tab on the top left of notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "colab_type": "code",
        "id": "01Djr8v-5pPk",
        "outputId": "56f8bf22-0d17-44ba-cd55-4667cb67ac3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# mount user's Google Drive to Google Colab.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8TkQcROufgwL"
      },
      "source": [
        "## **1.3. Install PSSR and dependencies**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "colab_type": "code",
        "id": "g5r0Gp7MwZLG",
        "outputId": "9dbb791f-1484-4091-f5b4-907652c0d0b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting czifile\n",
            "  Downloading https://files.pythonhosted.org/packages/37/86/3d0b1829c8c24eb1a4214f098a02442209f80302766203db33c99a4681ec/czifile-2019.7.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tifffile>=2019.7.2 in /usr/local/lib/python3.6/dist-packages (from czifile) (2020.6.3)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from czifile) (1.18.5)\n",
            "Installing collected packages: czifile\n",
            "Successfully installed czifile-2019.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install czifile\n",
        "!pip install fastai==1.0.61"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NS7lCdiQf_0T"
      },
      "source": [
        "## **1.4. Specify your working folder - need your input**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Vmx810jDXTbc"
      },
      "outputs": [],
      "source": [
        "root_path = \"gdrive/My Drive/PSSR-master\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GMetHM56gMkf"
      },
      "source": [
        "# **2. PSSR - Get to know your training data**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "vETWgkZ5v4dm"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(1, root_path)\n",
        "from fastai import *\n",
        "from fastai.vision import *\n",
        "from utils import *\n",
        "from pathlib import Path\n",
        "from fastprogress import master_bar, progress_bar\n",
        "from time import sleep\n",
        "import shutil\n",
        "import PIL\n",
        "import czifile\n",
        "PIL.Image.MAX_IMAGE_PIXELS = 99999999999999"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZCG3IlyEjzBa"
      },
      "source": [
        "## **2.1. Specify your datasource - need your input**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "VNZ7jTg7E5XK"
      },
      "outputs": [],
      "source": [
        "sources = ['datasources']\n",
        "output_file = 'live_mitotracker.csv'\n",
        "only = 'mitotracker'\n",
        "skip = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "rmTld6FTyqbE"
      },
      "outputs": [],
      "source": [
        "src_dirs = []\n",
        "for src in sources:\n",
        "    sub_fldrs = subfolders(Path(src))\n",
        "    if skip:  src_dirs += [fldr for fldr in sub_fldrs if fldr.stem not in skip]\n",
        "    elif only: src_dirs += [fldr for fldr in sub_fldrs if fldr.stem in only]\n",
        "    else: src_dirs += sub_fldrs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "szuxHh1XFnQs"
      },
      "outputs": [],
      "source": [
        "def process_czi(item, category, mode):\n",
        "#This function only takes the first channel of the czi files\n",
        "#since those are the only mitotracker channels\n",
        "    tif_srcs = []\n",
        "    base_name = item.stem\n",
        "    with czifile.CziFile(item) as czi_f:\n",
        "        data = czi_f.asarray()\n",
        "        axes, shape = get_czi_shape_info(czi_f)\n",
        "        channels = shape['C']\n",
        "        depths = shape['Z']\n",
        "        times = shape['T']\n",
        "        #times = min(times, 30) #ONLY USE FIRST 30 frames\n",
        "        x,y = shape['X'], shape['Y']\n",
        "\n",
        "        mid_depth = depths // 2\n",
        "        depth_range = range(max(0,mid_depth-2), min(depths, mid_depth+2))\n",
        "        is_multi = (times > 1) or (depths > 1)\n",
        "\n",
        "        data = czi_f.asarray()\n",
        "        all_rmax = data.max()\n",
        "        all_mi, all_ma = np.percentile(data, [2,99.99])\n",
        "\n",
        "        dtype = data.dtype\n",
        "        #for channel in range(channels): #if other channels are needed, use this line\n",
        "        for channel in range(0,1):\n",
        "            for z in depth_range:\n",
        "                for t in range(times):\n",
        "                    idx = build_index(\n",
        "                        axes, {\n",
        "                            'T': t,\n",
        "                            'C': channel,\n",
        "                            'Z': z,\n",
        "                            'X': slice(0, x),\n",
        "                            'Y': slice(0, y)\n",
        "                        })\n",
        "                    img = data[idx]\n",
        "                    mi, ma = np.percentile(img, [2,99.99])\n",
        "                    if dtype == np.uint8: rmax = 255.\n",
        "                    else: rmax = img.max()\n",
        "                    tif_srcs.append({'fn': item, 'ftype': 'czi', 'multi':int(is_multi), 'category': category, 'dsplit': mode,\n",
        "                                     'uint8': dtype == np.uint8, 'mi': mi, 'ma': ma, 'rmax': rmax,\n",
        "                                     'all_rmax': all_rmax, 'all_mi': all_mi, 'all_ma': all_ma,\n",
        "                                     'mean': img.mean(), 'sd': img.std(),\n",
        "                                     'nc': channels, 'nz': depths, 'nt': times,\n",
        "                                     'z': z, 't': t, 'c':channel, 'x': x, 'y': y})\n",
        "    return tif_srcs\n",
        "\n",
        "def is_live(item):\n",
        "    return item.parent.parts[-3] == 'live'\n",
        "\n",
        "def process_tif(item, category, mode):\n",
        "    tif_srcs = []\n",
        "    img = PIL.Image.open(item)\n",
        "    n_frames = img.n_frames\n",
        "    x,y = img.size\n",
        "    is_multi = n_frames > 1\n",
        "    #n_frames = min(n_frames, 30) #ONLY USE FIRST 30 frames\n",
        "\n",
        "    data = []\n",
        "    for n in range(n_frames):\n",
        "        img.seek(n)\n",
        "        img.load()\n",
        "        img_data = np.array(img)\n",
        "        data.append(img_data)\n",
        "\n",
        "    data = np.stack(data)\n",
        "    all_rmax = data.max()\n",
        "    all_mi, all_ma = np.percentile(data, [2,99.99])\n",
        "\n",
        "    for n in range(n_frames):\n",
        "        img_data = data[n]\n",
        "        dtype = img_data.dtype\n",
        "        mi, ma = np.percentile(img_data, [2,99.99])\n",
        "        if dtype == np.uint8: rmax = 255.\n",
        "        else: rmax = img_data.max()\n",
        "        if is_live(item):\n",
        "            t, z = n, 0\n",
        "            nt, nz = n_frames, 1\n",
        "        else:\n",
        "            t, z = 0, n\n",
        "            nt, nz = 1, n_frames\n",
        "\n",
        "        tif_srcs.append({'fn': item, 'ftype': 'tif', 'multi':int(is_multi), 'category': category, 'dsplit': mode,\n",
        "                         'uint8': dtype==np.uint8, 'mi': mi, 'ma': ma, 'rmax': rmax,\n",
        "                         'all_rmax': all_rmax, 'all_mi': all_mi, 'all_ma': all_ma,\n",
        "                         'mean': img_data.mean(), 'sd': img_data.std(),\n",
        "                         'nc': 1, 'nz': nz, 'nt': nt,\n",
        "                         'z': z, 't': t, 'c':0, 'x': x, 'y': y})\n",
        "    return tif_srcs\n",
        "\n",
        "def process_unk(item, category, mode):\n",
        "    print(f\"**** Unknown: {item}\")\n",
        "    return []\n",
        "\n",
        "def process_item(item, category, mode):\n",
        "    try:\n",
        "        if mode == 'test': return []\n",
        "        else:\n",
        "            item_map = {\n",
        "                '.tif': process_tif,\n",
        "                '.tiff': process_tif,\n",
        "                '.czi': process_czi,\n",
        "            }\n",
        "            map_f = item_map.get(item.suffix, process_unk)\n",
        "            return map_f(item, category, mode)\n",
        "    except Exception as ex:\n",
        "        print(f'err procesing: {item}')\n",
        "        print(ex)\n",
        "        return []\n",
        "\n",
        "def build_tifs(src, mbar=None):\n",
        "    tif_srcs = []\n",
        "    for mode in ['train', 'valid', 'test']:\n",
        "        live = src.parent.parts[-1] == 'live'\n",
        "        src_dir = src / mode\n",
        "        category = src.stem\n",
        "        items = list(src_dir.iterdir()) if src_dir.exists() else []\n",
        "        if items:\n",
        "            for p in progress_bar(items, parent=mbar):\n",
        "                mbar.child.comment = mode\n",
        "                tif_srcs += process_item(p, category=category, mode=mode)\n",
        "    return tif_srcs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "o7w1fzWrO5-v"
      },
      "outputs": [],
      "source": [
        "#pull metadata from datasources\n",
        "mbar = master_bar(src_dirs)\n",
        "tif_srcs = []\n",
        "for src in mbar:\n",
        "    mbar.write(f'process {src.stem}')\n",
        "    tif_srcs += build_tifs(src, mbar=mbar)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3UXIgrDn8bC6"
      },
      "outputs": [],
      "source": [
        "#save csv to disk\n",
        "tif_src_df = pd.DataFrame(tif_srcs)\n",
        "tif_src_df[['category','dsplit','multi','ftype','uint8','mean','sd','all_rmax','all_mi','all_ma','mi','ma','rmax','nc','nz','nt','c','z','t','x','y','fn']].to_csv(output_file, header=True, index=False)\n",
        "shutil.move(output_file, f'{root_path}/{output_file}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "PSSR 01 - Get to know your training data.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
